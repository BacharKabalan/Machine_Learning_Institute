{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import transformers as t\n",
    "import torch\n",
    "import peft\n",
    "import time\n",
    "import bash_data_train\n",
    "#%%\n",
    "ds = bash_data_train.TrainDataset()\n",
    "tokenizer = ds.tokenizer\n",
    "# tokenizer = t.AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\")\n",
    "# tokenizer.pad_token_id = 0\n",
    "base_model = t.AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-hf\", load_in_8bit=True, torch_dtype=torch.float16)\n",
    "print(len(tokenizer))\n",
    "#%%\n",
    "\n",
    "config = peft.PeftConfig.from_pretrained(\"./output/checkpoint-700\")\n",
    "model = peft.PeftModel.from_pretrained(base_model, \"./output/checkpoint-700\")\n",
    "\n",
    "# peft.set_peft_model_state_dict(model,\"./output/checkpoint-4900/adapter_config.json\")\n",
    "#%%\n",
    "\n",
    "########### ADD Template in a file\n",
    "TEMPLATE_YES_INPUT = \"Below is a question that describes a task paired with further context. Write a response that appropriately completes the request.\\n\\n### question:\\n{question}\\n\\n### context:\\n{context}\\n\\n### Response:\\n\"\n",
    "QUESTION = \"How many heads of the departments are older than 56 ?\"\n",
    "CONTEXT = \"CREATE TABLE head (age INTEGER)\"\n",
    "prompt = TEMPLATE_YES_INPUT.format(question=QUESTION, context=CONTEXT)\n",
    "#%%\n",
    "\n",
    "pipe = t.pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=500)\n",
    "print(pipe)\n",
    "# print(\"pipe(prompt)\", pipe(prompt))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
