{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347d5860-b062-4335-8ed9-7903e69a2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 47706, done.\u001b[K\n",
      "remote: Counting objects: 100% (1553/1553), done.\u001b[K\n",
      "remote: Compressing objects: 100% (693/693), done.\u001b[K\n",
      "remote: Total 47706 (delta 1016), reused 1150 (delta 731), pack-reused 46153\u001b[K\n",
      "Receiving objects: 100% (47706/47706), 31.87 MiB | 7.83 MiB/s, done.\n",
      "Resolving deltas: 100% (35158/35158), done.\n",
      "Processing ./diffusers\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7)) (2.1.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r ./diffusers/examples/dreambooth/requirements.txt (line 3)) (2023.10.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers>=4.25.1->-r ./diffusers/examples/dreambooth/requirements.txt (line 3))\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->-r ./diffusers/examples/dreambooth/requirements.txt (line 4))\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting protobuf<4.24,>=3.19.6 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r ./diffusers/examples/dreambooth/requirements.txt (line 6)) (2.1.2)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r ./diffusers/examples/dreambooth/requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r ./diffusers/examples/dreambooth/requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r ./diffusers/examples/dreambooth/requirements.txt (line 2)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r ./diffusers/examples/dreambooth/requirements.txt (line 2)) (2022.12.7)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5))\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r ./diffusers/examples/dreambooth/requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r ./diffusers/examples/dreambooth/requirements.txt (line 7)) (1.3.0)\n",
      "Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m808.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wcwidth, werkzeug, tensorboard-data-server, pyasn1, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown, grpcio, ftfy, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, google-auth, transformers, torch, google-auth-oauthlib, torchvision, tensorboard, accelerate, peft\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.9\n",
      "    Uninstalling wcwidth-0.2.9:\n",
      "      Successfully uninstalled wcwidth-0.2.9\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0+cu118\n",
      "    Uninstalling torchvision-0.16.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.0.0 accelerate-0.25.0 cachetools-5.3.2 ftfy-6.1.3 google-auth-2.25.2 google-auth-oauthlib-1.2.0 grpcio-1.60.0 markdown-3.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 peft-0.7.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tokenizers-0.15.0 torch-2.1.1 torchvision-0.16.1 transformers-4.36.0 wcwidth-0.2.12 werkzeug-3.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers.git\n",
    "!pip install ./diffusers\n",
    "!pip install -U -r ./diffusers/examples/dreambooth/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed3d23a-2f1f-4cab-ab22-52c92d0f9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425a0e25-186c-480b-9e42-5df219554910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5553bbba94bb5b9dc627e7ce97e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0833b48a-fbd8-4ce7-a7bb-25207881c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 24245 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8aa7ee-c589-44ad-a993-0012ea7765d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import plot_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859bdb00-2dab-4407-8a45-22cb433cb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 23887 MiB\n",
      "100\n",
      "12/13/2023 13:28:11 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'timestep_spacing', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value', 'prediction_type', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "{'norm_num_groups', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type', 'conv_in_kernel', 'dropout', 'time_cond_proj_dim', 'dual_cross_attention', 'upcast_attention', 'conv_out_kernel', 'addition_embed_type_num_heads', 'timestep_post_act', 'resnet_time_scale_shift', 'only_cross_attention', 'num_class_embeds', 'num_attention_heads', 'use_linear_projection', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'mid_block_type', 'transformer_layers_per_block', 'resnet_skip_time_act', 'time_embedding_dim', 'time_embedding_act_fn', 'resnet_out_scale_factor', 'attention_type', 'addition_time_embed_dim', 'cross_attention_norm', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'reverse_transformer_layers_per_block', 'class_embed_type', 'encoder_hid_dim_type', 'class_embeddings_concat'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 13:28:13 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Num examples = 6\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Num batches each epoch = 6\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Num Epochs = 17\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "12/13/2023 13:28:13 - INFO - __main__ -   Total optimization steps = 100\n",
      "Steps: 100%|███████████| 100/100 [00:33<00:00,  3.05it/s, loss=0.00282, lr=5e-6]{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "{'norm_num_groups', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "\n",
      "Loading pipeline components...:  57%|███████▍     | 4/7 [00:00<00:00, 38.77it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:00<00:00, 31.55it/s]\n",
      "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "Configuration saved in ./dreambooth/run2/vae/config.json\n",
      "Model weights saved in ./dreambooth/run2/vae/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in ./dreambooth/run2/unet/config.json\n",
      "Model weights saved in ./dreambooth/run2/unet/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in ./dreambooth/run2/scheduler/scheduler_config.json\n",
      "Configuration saved in ./dreambooth/run2/model_index.json\n",
      "Steps: 100%|███████████| 100/100 [00:37<00:00,  2.67it/s, loss=0.00282, lr=5e-6]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed40a17a5fdf43fdbad6f1550b48e0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a611f3e06d46d7a0c4e3e8b8149bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1519cbc93dd049b09d944f32846f2d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ea9ef3f914447cad480d33b6bcdea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5de219dffd44d2e94f9c194b52ad51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507e143afdb349199242a99e4828566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 15063 MiB\n",
      "200\n",
      "12/13/2023 13:29:10 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'timestep_spacing', 'dynamic_thresholding_ratio', 'sample_max_value', 'prediction_type', 'thresholding', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
      "{'timestep_post_act', 'time_cond_proj_dim', 'transformer_layers_per_block', 'num_attention_heads', 'resnet_time_scale_shift', 'projection_class_embeddings_input_dim', 'only_cross_attention', 'resnet_skip_time_act', 'encoder_hid_dim', 'mid_block_type', 'use_linear_projection', 'addition_embed_type', 'time_embedding_type', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'resnet_out_scale_factor', 'conv_in_kernel', 'encoder_hid_dim_type', 'addition_embed_type_num_heads', 'time_embedding_dim', 'mid_block_only_cross_attention', 'class_embeddings_concat', 'dropout', 'attention_type', 'upcast_attention', 'cross_attention_norm', 'class_embed_type', 'conv_out_kernel', 'time_embedding_act_fn', 'num_class_embeds', 'dual_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 13:29:12 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Num examples = 6\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Num batches each epoch = 6\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Num Epochs = 34\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "12/13/2023 13:29:12 - INFO - __main__ -   Total optimization steps = 200\n",
      "Steps:   0%|                                            | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1428, in <module>\n",
      "    main(args)\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1314, in main\n",
      "    optimizer.step()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 132, in step\n",
      "    self.scaler.step(self.optimizer, closure)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 416, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 315, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 185, in patched_step\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 184, in step\n",
      "    adamw(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 335, in adamw\n",
      "    func(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 599, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 6.81 MiB is free. Process 3850780 has 8.96 GiB memory in use. Process 3851277 has 14.70 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 153.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Steps:   0%|                                            | 0/200 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1017, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 637, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python', './diffusers/examples/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=./bash_images', '--output_dir=./dreambooth/run4', '--instance_prompt=a photo of brk1', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=200']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c20f2500534c0682cbc963cae25b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61351d4c4106486ab6e6ba7f81ff48df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc5e62953b844c0aab552a811ab989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206cac58d7984a99be0fa40357bb5faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260c08ac79ba46539a49cbc866b80482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b0713cc0194901ad00bd00b110ab3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 15063 MiB\n",
      "300\n",
      "12/13/2023 13:29:34 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'sample_max_value', 'thresholding', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio', 'clip_sample_range', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
      "{'time_embedding_act_fn', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'resnet_out_scale_factor', 'dual_cross_attention', 'mid_block_only_cross_attention', 'time_embedding_type', 'encoder_hid_dim_type', 'class_embeddings_concat', 'time_embedding_dim', 'transformer_layers_per_block', 'addition_time_embed_dim', 'only_cross_attention', 'mid_block_type', 'cross_attention_norm', 'dropout', 'encoder_hid_dim', 'reverse_transformer_layers_per_block', 'time_cond_proj_dim', 'class_embed_type', 'num_attention_heads', 'resnet_skip_time_act', 'conv_in_kernel', 'resnet_time_scale_shift', 'conv_out_kernel', 'addition_embed_type', 'timestep_post_act', 'attention_type', 'addition_embed_type_num_heads', 'use_linear_projection', 'upcast_attention'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 13:29:36 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Num examples = 6\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Num batches each epoch = 6\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Num Epochs = 50\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "12/13/2023 13:29:36 - INFO - __main__ -   Total optimization steps = 300\n",
      "Steps:   0%|                                            | 0/300 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1428, in <module>\n",
      "    main(args)\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1314, in main\n",
      "    optimizer.step()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 132, in step\n",
      "    self.scaler.step(self.optimizer, closure)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 416, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 315, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 185, in patched_step\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 184, in step\n",
      "    adamw(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 335, in adamw\n",
      "    func(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 599, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 6.81 MiB is free. Process 3850780 has 8.96 GiB memory in use. Process 3851359 has 14.70 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 153.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Steps:   0%|                                            | 0/300 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1017, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 637, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python', './diffusers/examples/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=./bash_images', '--output_dir=./dreambooth/run6', '--instance_prompt=a photo of brk1', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=300']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae35e5bb95c2485ebc058b109f147276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bc9f5599bb446798eaa8340251f77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14394a495a1a49ef8db5280250a6c214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88552bb5b9ec4e8a97ce25d5dce1bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a827d13d8f24490aaf912dc3bab86866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3843896c184c348a0c45061fd1deff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 15063 MiB\n",
      "400\n",
      "12/13/2023 13:29:57 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'dynamic_thresholding_ratio', 'thresholding', 'prediction_type', 'timestep_spacing', 'clip_sample_range', 'variance_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_time_embed_dim', 'addition_embed_type', 'resnet_out_scale_factor', 'time_embedding_dim', 'addition_embed_type_num_heads', 'conv_in_kernel', 'mid_block_type', 'class_embeddings_concat', 'cross_attention_norm', 'time_embedding_type', 'conv_out_kernel', 'num_attention_heads', 'reverse_transformer_layers_per_block', 'dual_cross_attention', 'projection_class_embeddings_input_dim', 'only_cross_attention', 'resnet_skip_time_act', 'timestep_post_act', 'dropout', 'use_linear_projection', 'upcast_attention', 'encoder_hid_dim', 'num_class_embeds', 'time_cond_proj_dim', 'class_embed_type', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'encoder_hid_dim_type', 'attention_type', 'mid_block_only_cross_attention', 'transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 13:29:59 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Num examples = 6\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Num batches each epoch = 6\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Num Epochs = 67\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "12/13/2023 13:29:59 - INFO - __main__ -   Total optimization steps = 400\n",
      "Steps:   0%|                                            | 0/400 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1428, in <module>\n",
      "    main(args)\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1314, in main\n",
      "    optimizer.step()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 132, in step\n",
      "    self.scaler.step(self.optimizer, closure)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 416, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 315, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 185, in patched_step\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 184, in step\n",
      "    adamw(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 335, in adamw\n",
      "    func(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 599, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 6.81 MiB is free. Process 3850780 has 8.96 GiB memory in use. Process 3851437 has 14.70 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 153.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Steps:   0%|                                            | 0/400 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1017, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 637, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python', './diffusers/examples/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=./bash_images', '--output_dir=./dreambooth/run8', '--instance_prompt=a photo of brk1', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=400']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14a92ac82754bc787d7e4ed0845760c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8109cccd3b804afa9b325ac960e214d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf3721451aa454780daf7322fd36dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d8ced01e2241bb8720de6686869917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2ddddc8ce84f82815e7b5034b3b8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6103d26039924ae39f452f5e72621328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "name, memory.total [MiB], memory.free [MiB]\n",
      "NVIDIA GeForce RTX 3090 Ti, 24564 MiB, 15063 MiB\n",
      "500\n",
      "12/13/2023 13:30:20 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'variance_type', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'norm_num_groups', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'attention_type', 'encoder_hid_dim_type', 'resnet_out_scale_factor', 'dropout', 'reverse_transformer_layers_per_block', 'mid_block_only_cross_attention', 'addition_embed_type', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'use_linear_projection', 'addition_time_embed_dim', 'num_class_embeds', 'upcast_attention', 'transformer_layers_per_block', 'time_embedding_dim', 'encoder_hid_dim', 'only_cross_attention', 'mid_block_type', 'class_embed_type', 'timestep_post_act', 'conv_out_kernel', 'cross_attention_norm', 'time_embedding_type', 'conv_in_kernel', 'resnet_skip_time_act', 'dual_cross_attention', 'num_attention_heads'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 13:30:22 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Num examples = 6\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Num batches each epoch = 6\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Num Epochs = 84\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "12/13/2023 13:30:22 - INFO - __main__ -   Total optimization steps = 500\n",
      "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1428, in <module>\n",
      "    main(args)\n",
      "  File \"/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/./diffusers/examples/dreambooth/train_dreambooth.py\", line 1314, in main\n",
      "    optimizer.step()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 132, in step\n",
      "    self.scaler.step(self.optimizer, closure)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 416, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 315, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\", line 185, in patched_step\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 184, in step\n",
      "    adamw(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 335, in adamw\n",
      "    func(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 599, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 6.81 MiB is free. Process 3850780 has 8.96 GiB memory in use. Process 3851529 has 14.70 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 153.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Steps:   0%|                                            | 0/500 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1017, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 637, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python', './diffusers/examples/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=./bash_images', '--output_dir=./dreambooth/run10', '--instance_prompt=a photo of brk1', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=500']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd59527abf5f4ee28f2af1a7af2db0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf2284372154468a87a88464ebb54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate launch ./diffusers/examples/dreambooth/train_dreambooth.py        --pretrained_model_name_or_path=$MODEL_NAME         --instance_data_dir=$INSTANCE_DIR        --output_dir=$OUTPUT_DIR        --instance_prompt=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma photo of brk1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        --resolution=512        --train_batch_size=1        --gradient_accumulation_steps=1        --learning_rate=5e-6        --lr_scheduler=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        --lr_warmup_steps=0        --max_train_steps=$TRAIN_STEPS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dreambooth/run\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mplot_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplotting_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m grid\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./grid_run_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/Machine_Learning_Institute/week8_fine_tune_stable_diffusion/dreambooth/plot_grid.py:10\u001b[0m, in \u001b[0;36mplotting_grid\u001b[0;34m(model_id)\u001b[0m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m      9\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableDiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m pipe_base \u001b[38;5;241m=\u001b[39m \u001b[43mStableDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCompVis/stable-diffusion-v1-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pipe\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m pipe_base\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:1271\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m passed_class_obj[name]\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;66;03m# load sub model\u001b[39;00m\n\u001b[0;32m-> 1271\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_sub_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimportable_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimportable_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_pipeline_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_pipeline_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msess_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msess_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_variants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcached_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` subfolder of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1295\u001b[0m     )\n\u001b[1;32m   1297\u001b[0m init_kwargs[name] \u001b[38;5;241m=\u001b[39m loaded_sub_model  \u001b[38;5;66;03m# UNet(...), # DiffusionSchedule(...)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:525\u001b[0m, in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, revision)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# check if the module is in a subdirectory\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cached_folder, name)):\n\u001b[0;32m--> 525\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloading_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# else load from the root directory\u001b[39;00m\n\u001b[1;32m    528\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m load_method(cached_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloading_kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3381\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n\u001b[1;32m   3379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded \u001b[38;5;129;01mand\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3380\u001b[0m         \u001b[38;5;66;03m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> 3381\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3383\u001b[0m     \u001b[38;5;66;03m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   3384\u001b[0m     \u001b[38;5;66;03m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   3385\u001b[0m     \u001b[38;5;66;03m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   3386\u001b[0m     \u001b[38;5;66;03m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   3387\u001b[0m     \u001b[38;5;66;03m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   3388\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:519\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1357\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1357\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  # Force garbage collection\n",
    "\n",
    "\n",
    "for i in range(2,22,2):\n",
    "    import torch\n",
    "    import gc\n",
    "    import os\n",
    "    import plot_grid\n",
    "    !accelerate config default --mixed_precision fp16\n",
    "    \n",
    "    !nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "    os.environ['MODEL_NAME'] = 'CompVis/stable-diffusion-v1-4'\n",
    "    os.environ['INSTANCE_DIR'] = './bash_images'\n",
    "    os.environ['OUTPUT_DIR'] = f'./dreambooth/run{i}'\n",
    "    os.environ['TRAIN_STEPS'] = str(i*50)\n",
    "    print(i*50)\n",
    "    !accelerate launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "      --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "      --instance_data_dir=$INSTANCE_DIR \\\n",
    "      --output_dir=$OUTPUT_DIR \\\n",
    "      --instance_prompt=\"a photo of brk1\" \\\n",
    "      --resolution=512 \\\n",
    "      --train_batch_size=1 \\\n",
    "      --gradient_accumulation_steps=1 \\\n",
    "      --learning_rate=5e-6 \\\n",
    "      --lr_scheduler=\"constant\" \\\n",
    "      --lr_warmup_steps=0 \\\n",
    "      --max_train_steps=$TRAIN_STEPS\n",
    "\n",
    "    model_id = f\"./dreambooth/run{i}\"\n",
    "    grid = plot_grid.plotting_grid(model_id)\n",
    "    grid.save(f'./grid_run_{i}.png')\n",
    "    %reset -f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cd11c-72b4-4933-b99b-f9fe211db0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
