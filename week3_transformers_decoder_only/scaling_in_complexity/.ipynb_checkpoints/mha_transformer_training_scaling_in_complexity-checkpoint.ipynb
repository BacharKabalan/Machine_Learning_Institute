{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "import dataset_bes_train\n",
    "import dataset_bes_val\n",
    "import tokenizer_bes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bash_gpt\n",
    "import time\n",
    "from torch.autograd import profiler\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/bash1989/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-6ac769f186d7da53/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a7c808d569460eafa0bb44729b09f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/bash1989/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-6ac769f186d7da53/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d87417d5b8408cb7dc518857d9e968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tk = (tokenizer_bes.TinyTokenizer()).load()\n",
    "ds = dataset_bes_train.TinyDataset()\n",
    "val_ds = dataset_bes_val.TinyDataset()\n",
    "batch_size = 4\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=ds.collate_fn)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=True, collate_fn=ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer_model = bash_gpt.GPT().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=lr, eps=1e-9, betas=(0.9,.98))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26468480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in transformer_model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "checkpoint_interval = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb.login(key=\"9091f9245cf64052fa6d4eae03190a076fd87fe8\")\n",
    "# wandb.init(name = f'{transformer_model.num_heads} Head(s), params = {total_params:,}',project ='mlx_transformer_GPT', entity = 'basharkabalan',     config={\n",
    "#     \"learning_rate\": lr,\n",
    "#     \"architecture\": \"Trans_Bash\",\n",
    "#     \"dataset\": \"roneneldan/TinyStories\",\n",
    "#     \"epochs\": num_epochs,\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_at = wandb.Artifact(\"test_samples_\" + str(wandb.run.id), type=\"predictions\")\n",
    "# columns=[\"id\", \"word\", \"truth\", \"guess\"]\n",
    "# test_table = wandb.Table(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"logs/profile_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-14 17:41:03 3126:3126 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 7.8215\n",
      "train_loss: 6.6312, val_loss: 6.6312, val_acc: 0.2759\n",
      "Epoch 1/5, val_acc: 0.27586206793785095, val_loss: 6.63116455078125\n",
      "train_loss: 7.9044\n",
      "train_loss: 6.9659, val_loss: 6.9659, val_acc: 0.2265\n",
      "Epoch 2/5, val_acc: 0.22648514807224274, val_loss: 6.965888500213623\n",
      "train_loss: 6.4986\n",
      "train_loss: 5.2808, val_loss: 5.2808, val_acc: 0.4341\n",
      "Epoch 3/5, val_acc: 0.43408361077308655, val_loss: 5.280822277069092\n",
      "train_loss: 6.6681\n",
      "train_loss: 7.1080, val_loss: 7.1080, val_acc: 0.1478\n",
      "Epoch 4/5, val_acc: 0.14779874682426453, val_loss: 7.107951641082764\n",
      "train_loss: 4.4355\n",
      "train_loss: 3.8390, val_loss: 3.8390, val_acc: 0.5234\n",
      "Epoch 5/5, val_acc: 0.5233852863311768, val_loss: 3.8389577865600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-14 17:41:07 3126:3126 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-14 17:41:07 3126:3126 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        transformer_model.train()\n",
    "        for idx, batch in enumerate(dl):\n",
    "    #         start_time = time.time()\n",
    "\n",
    "            tokens = batch['input'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output= transformer_model(tokens)\n",
    "            model_output = output.view(-1, output.size(-1))  # Reshape to [batch_size * seq_length, num_classes]\n",
    "            true_labels = labels.view(-1)  # Reshape to [batch_size * seq_length]\n",
    "            loss = loss_function(model_output, true_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #         print(time.time()-start_time)\n",
    "            if idx % 500 == 0:\n",
    "                    print(f\"train_loss: {loss:.4f}\")\n",
    "    #                 wandb.log({\"train_loss\": loss})\n",
    "                    break\n",
    "            if idx % 5000 == 0: torch.save(transformer_model.state_dict(), f\"multi_head_with_pos_encod_weights_{epoch}_{idx}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "        transformer_model.eval()\n",
    "        val_correct_predictions = torch.tensor(0)\n",
    "        val_correct_predictions = val_correct_predictions.to(device)\n",
    "        val_total_predictions = torch.tensor(0)\n",
    "        val_total_predictions = val_total_predictions.to(device)\n",
    "        with torch.no_grad():\n",
    "            for val_idx, val_batch in enumerate(val_dl):\n",
    "                val_tokens = val_batch['input'].to(device)\n",
    "                val_labels = val_batch['label'].to(device)\n",
    "                val_output= transformer_model(val_tokens)\n",
    "                val_model_output = val_output.view(-1, val_output.size(-1))  # Reshape to [batch_size * seq_length, num_classes]\n",
    "                val_true_labels = val_labels.view(-1)  # Reshape to [batch_size * seq_length]\n",
    "                val_loss = loss_function(val_model_output, val_true_labels)\n",
    "                val_max_indices = torch.argmax(val_model_output, dim=1)\n",
    "                val_correct_predictions += ((val_max_indices - val_true_labels)==0).sum()\n",
    "                val_total_predictions += len(val_true_labels)\n",
    "\n",
    "                if idx % 500 == 0:\n",
    "\n",
    "                    val_acc = val_correct_predictions/val_total_predictions\n",
    "                    print(f\"train_loss: {val_loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}\")\n",
    "                    break\n",
    "    #                 wandb.log({\"train_loss\": loss,\"val_acc\": val_acc, \"val_loss\": val_loss})\n",
    "                    # wandb.run.log_artifact(test_data_at)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # if idx%100 == 0:\n",
    "            #     test_table.add_data(tokens[0][3],  tk.decode(tokens[0][3].item()), tk.decode(true_labels[3].item()),  tk.decode(max_indices[3].item()))\n",
    "            #     test_data_at.add(test_table, \"predictions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': transformer_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss\n",
    "            }, checkpoint_path)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, val_acc: {val_acc}, val_loss: {val_loss.item()}\")\n",
    "\n",
    "    \n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "# writer.add_text('Profiler Info', prof.key_averages().table(sort_by='cuda_time_total'))\n",
    "writer.add_text('Profiler Info', prof.key_averages().table(sort_by='cuda_time_total'))\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d2df03a2967616e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d2df03a2967616e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/profile_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
